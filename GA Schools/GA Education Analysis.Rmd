---
title: "GA Education Analysis "
author: "Ethan Shen"
date: "6/8/2020"
output: 
  html_document:
    keep_md: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message=F,
                      warning=F)
library(tidyverse)
library(spdep)
library(sf)
library(spatialreg)
library(patchwork)
ggplot2::theme_set(theme_bw())
```

This project seeks to predict the average graduation rate of high schools in each county in GA. 

# Data

```{r}
init_schools = st_read("data/schools_2009/DOE Schools 2009.shp", quiet=T)
init_counties = st_read("data/Counties_Georgia-shp/Counties_Georgia.shp", quiet=T)
school_names = read_csv("data/school-19.csv")

par(mfrow = c(1,2))
plot(st_geometry(init_schools), main="Schools")
plot(st_geometry(init_counties), main="Counties")
```

The `schools` dataset has some schools which are not in GA. We fix that issue first. 

```{r}
schools = st_intersection(init_schools %>% 
                            st_transform(st_crs(init_counties)), 
                          init_counties
) %>% 
  filter(GRADES == "09,10,11,12")
plot(st_geometry(schools), pch=16, main="Schools")
```

This looks like the shape of GA.

```{r}
schools_data = inner_join(init_schools, school_names, by = c("SCHOOLNAME" = "SchoolName"))

counties_data = inner_join(init_counties, school_names, by = c("NAMELSAD10" = "SystemName"))
```

```{r}
ggplot() + 
  geom_sf(data = schools, alpha=0.6) +
  geom_sf(data = init_counties, fill=NA, col="black") + 
  geom_sf(data = init_counties %>% filter(NAME10 == "Forsyth"), fill = "lightblue", col="black") +
  geom_sf(data = schools %>% filter(SCHOOLNAME == "South Forsyth High School"), color = "blue") + 
  labs(title = "High Schools in GA",
       subtitle = "Forsyth County & SFHS")
```

## Wrangling Data 

I am only select data that is pertinent to a school's demographic and other variables that are relevant to a high school's performance. Then, I am calculating the average graduation rate for each county. 

```{r}
grad_rate = counties_data %>% 
  # filter(Grades %in% 
  #          counties_data$Grades[str_detect(counties_data$Grades, "12")]) %>%
  # filter(Grades=="9-12") %>%
  select(NAME10, total_enroll, SingleScore:pct_lep, Graduation_RateH,  English_BegH:Four_Year_Graduation_Rate, FinancialEfficiency:geometry) %>% 
  #select(NAME10, Graduation_RateH, Accelerated_Course_Taking, geometry) %>% 
  mutate_if(is.character, as.numeric) %>%  
  group_by(NAME10) %>%
  summarise_if(is.numeric, mean, na.rm=TRUE) %>% 
  filter(!is.na(Graduation_RateH))
```

# EDA 

```{r}
par(mfrow=c(2,2))
hist(grad_rate$Graduation_RateH, main="", xlab="")
hist(max(grad_rate$Graduation_RateH) + 1 - grad_rate$Graduation_RateH, main="", xlab="")
hist(log(max(grad_rate$Graduation_RateH) + 1 - grad_rate$Graduation_RateH), main="", xlab="")
```

It seems like the last transformation looks the most "normal". I will use the transformed version, `Graduation_RateH_transformed`, in my analysis. 

```{r}
grad_rate = grad_rate %>% 
  mutate(Graduation_RateH_transformed = log(max(grad_rate$Graduation_RateH) + 1 - grad_rate$Graduation_RateH))
```

```{r}
gridExtra::grid.arrange(
  ggplot() + 
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data = grad_rate, aes(fill=Graduation_RateH)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Graduation Rate"),
  ggplot() + 
    geom_sf(data=init_counties, fill=NA) +  
    geom_sf(data = grad_rate, aes(fill=Graduation_RateH_transformed)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Transformed Graduation Rate"),
  ncol=2)
```

## Creating Weight Matrix 

```{r}
W = st_touches(grad_rate, sparse = FALSE)
listW = mat2listw(W)

plot(st_geometry(grad_rate))
plot(listW, st_geometry(st_centroid(grad_rate)), pch=16, col="blue", add=TRUE)
```

## Moran's and Geary's 

```{r}
moran.test(grad_rate$Graduation_RateH_transformed, listW)
geary.test(grad_rate$Graduation_RateH_transformed, listW)
```

From both the Moran's I and Geary's C statistics, it shows that there is slight **positive** autocorrelation with `Graduation_RateH_transformed`.

# Frequentist Linear Model 

In the eventual CAR model(s), I want use other variables to help predict `Graduation_RateH_transformed`. Thus, I am performing backwards selection with a BIC criterion to pick variables that are important. These variables will be included in the last Bayesian CAR model. 

```{r}
library(leaps)
model_data = grad_rate %>% 
  tbl_df() %>%
  select(-geometry) 

model_select <- regsubsets(Graduation_RateH_transformed ~. -NAME10 - Graduation_RateH - Four_Year_Graduation_Rate, data = model_data, na.action=na.exclude, method = "backward")

coef(model_select, which.min(summary(model_select)$bic))
```

```{r}
model_data = model_data %>% 
  select(Graduation_RateH_transformed, pct_hispanic, pct_white, 
         pct_lep, English_BegH, College_Readiness, PPE) 

model_data[is.nan(model_data$English_BegH),]$English_BegH = median(model_data$English_BegH, na.rm=TRUE)

model = lm(Graduation_RateH_transformed ~ pct_hispanic + pct_white + pct_lep + English_BegH + College_Readiness + PPE, data = model_data)
summary(model)
```

## Prediction

```{r}
grad_rate_modeling = grad_rate %>%
  select(NAME10, Graduation_RateH_transformed, Graduation_RateH, pct_hispanic, pct_white, pct_lep, English_BegH,College_Readiness, PPE)

grad_rate_modeling[is.nan(grad_rate_modeling$English_BegH),]$English_BegH = median(grad_rate_modeling$English_BegH, na.rm=TRUE)
```

```{r}
grad_rate_modeling$lm_log_pred = model %>% fitted()
grad_rate_modeling$lm_log_resid = model %>% residuals()
grad_rate_modeling$lm_pred = max(grad_rate_modeling$Graduation_RateH) + 1 - exp(grad_rate_modeling$lm_log_pred) 

gridExtra::grid.arrange(
  ggplot() + 
    geom_sf(data=grad_rate_modeling, aes(fill=lm_log_pred)) + 
    labs(title = "Log LM Predictions") + 
    geom_sf(data=init_counties, fill=NA)+
    scale_fill_continuous(na.value="white")
  ,
  ggplot() + 
    geom_sf(data=grad_rate_modeling, aes(fill=lm_pred)) + 
    labs(title = "LM Predictions") + 
    geom_sf(data=init_counties, fill=NA)+
    scale_fill_continuous(na.value="white"),
  ncol=2
)
```

# Frequentist SAR & CAR Model 

```{r}
listW_neigh = nb2listw(listW$neighbours, style = "B")
#eigs = eigenw(listW_neigh)

grad_rate_sar = spautolm(formula = Graduation_RateH_transformed ~ pct_hispanic + pct_white + pct_lep + English_BegH + College_Readiness + PPE,
                         data=grad_rate_modeling,
                         listw = listW_neigh,
                         family = "SAR")
summary(grad_rate_sar)

grad_rate_car = spautolm(formula = Graduation_RateH_transformed ~ pct_hispanic + pct_white + pct_lep + English_BegH + College_Readiness + PPE,
                         data=grad_rate_modeling,
                         listw = listW_neigh,
                         family = "CAR")
summary(grad_rate_car)
```

## Prediction 

```{r}
grad_rate_modeling$sar_pred_log = grad_rate_sar$fit$fitted.values
grad_rate_modeling$car_pred_log = grad_rate_car$fit$fitted.values

grad_rate_modeling$sar_pred = max(grad_rate_modeling$Graduation_RateH) + 1 - exp(grad_rate_modeling$sar_pred_log) 

grad_rate_modeling$car_pred = max(grad_rate_modeling$Graduation_RateH) + 1 - exp(grad_rate_modeling$car_pred_log) 

gridExtra::grid.arrange(
  ggplot() + 
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=sar_pred_log)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Log SAR Predictions"),
   ggplot() + 
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=sar_pred)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "SAR Predictions"),
  ncol=2
) 

gridExtra::grid.arrange(
  ggplot() + 
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=car_pred_log)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Log CAR Predictions"),
  ggplot() + 
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=car_pred)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "CAR Predictions"),
  ncol=2
) 
```

## Residuals

```{r}
grad_rate_modeling$sar_log_resid = grad_rate_sar$fit$residuals
grad_rate_modeling$car_log_resid = grad_rate_car$fit$residuals

gridExtra::grid.arrange(
  ggplot() + 
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=sar_log_resid)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "SAR Residuals",
         subtitle = paste0("Moran's I: ", 
                           round(moran.test(grad_rate_modeling$sar_log_resid, 
                                            listW_neigh, 
                                            na.action = na.exclude)$estimate[1],3))),
  ggplot() + 
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=car_log_resid)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "CAR Residuals",
         subtitle = paste0("Moran's I: ", 
                           round(moran.test(grad_rate_modeling$car_log_resid, 
                                            listW_neigh, 
                                            na.action = na.exclude)$estimate[1],3))),
  ncol=2
) 
```

```{r include=FALSE}
# Bayesian CAR Model - Untransformed
car_model = "
data {
  int<lower=0> N;
  vector[N] y;
  matrix[N,N] W;
  matrix[N,N] D;
}
parameters {
  vector[N] w_s;
  real beta;
  real<lower=0> sigma2; // variance in CAR part of model 
  real<lower=0> sigma2_w; // additional source of error so we get normal model
  real<lower=0,upper=1> phi;
}
transformed parameters {
  vector[N] y_pred = beta + w_s;
}
model {
  matrix[N,N] Sigma_inv = (D - phi * W) / sigma2; 
  w_s ~ multi_normal_prec(rep_vector(0,N), Sigma_inv); 

  beta ~ normal(0,10);
  sigma2 ~ cauchy(0,5);
  sigma2_w ~ cauchy(0,5);
  
  y ~ normal(beta+w_s, sigma2_w);
}
"

if (!file.exists("stan_car1.rds")) {
  car_fit = rstan::stan(
    model_code = car_model, 
    data = list(
      N = nrow(grad_rate),
      y = grad_rate$Graduation_RateH,
      W = W * 1,
      D = diag(rowSums(W))
    ),
    iter = 20000, 
    chains = 1, 
    thin=20
  )
  saveRDS(car_fit, "stan_car1.rds")
} else {
  car_fit = readRDS("stan_car1.rds")
}

tidybayes::gather_draws(car_fit, beta, phi, sigma2, sigma2_w) %>% 
  ggplot() +
  geom_line(aes(x=.iteration, y=.value, color=.variable)) +
  facet_grid(.variable~., scales = "free_y") +
  guides(color=FALSE)

grad_rate_modeling$bayes_car_pred = tidybayes::gather_draws(car_fit, y_pred[i]) %>%
  ungroup() %>%
  group_by(i) %>% 
  summarize(
    bayes_car_pred = mean(.value)
  ) %>%
  pull(bayes_car_pred)

grad_rate_modeling$bayes_car_resid = grad_rate_modeling$Graduation_RateH - grad_rate_modeling$bayes_car_pred


gridExtra::grid.arrange(
  ggplot() +  
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=bayes_car_pred)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Bayesian CAR Predictions", 
         subtitle = paste0("RMSE: ",
                           grad_rate_modeling$bayes_car_resid %>% 
                             .^2 %>% 
                             mean() %>% 
                             sqrt() %>% 
                             round(3)
         )),
  ggplot() +  
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=bayes_car_resid)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Bayesian CAR Residuals",
         subtitle = paste0("Moran's I: ", 
                           round(moran.test(grad_rate_modeling$bayes_car_resid, 
                                            listW_neigh, 
                                            na.action = na.exclude)$estimate[1],3)
         )),
  ncol=2
) 
```

# Bayesian CAR Model - Transformed

```{r}
car_model = "
data {
  int<lower=0> N;
  vector[N] y;
  matrix[N,N] W;
  matrix[N,N] D;
}
parameters {
  vector[N] w_s;
  real beta;
  real<lower=0> sigma2; // variance in CAR part of model 
  real<lower=0> sigma2_w; // additional source of error so we get normal model
  real<lower=0,upper=1> phi;
}
transformed parameters {
  vector[N] y_pred = beta + w_s;
}
model {
  matrix[N,N] Sigma_inv = (D - phi * W) / sigma2; 
  w_s ~ multi_normal_prec(rep_vector(0,N), Sigma_inv); 

  beta ~ normal(0,10);
  sigma2 ~ cauchy(0,5);
  sigma2_w ~ cauchy(0,5);
  
  y ~ normal(beta+w_s, sigma2_w);
}
"
```

```{r}
if (!file.exists("stan_car2.rds")) {
  car_fit2 = rstan::stan(
    model_code = car_model, 
    data = list(
      N = nrow(grad_rate),
      y = grad_rate$Graduation_RateH_transformed,
      W = W * 1,
      D = diag(rowSums(W))
    ),
    iter = 50000, 
    chains = 1, 
    thin=50
  )
  saveRDS(car_fit2, "stan_car2.rds")
} else {
  car_fit2 = readRDS("stan_car2.rds")
}
```

## MCMC Diagnostics 

```{r}
tidybayes::gather_draws(car_fit2, beta, phi, sigma2, sigma2_w) %>% 
  ggplot() +
  geom_line(aes(x=.iteration, y=.value, color=.variable)) +
  facet_grid(.variable~., scales = "free_y") +
  guides(color=FALSE)
```

The chains generally look fine. `sigma2` and `sigma2_w` are pretty correlated. 

## Prediction & Residuals

```{r}
grad_rate_modeling$bayes_car_log_pred = tidybayes::gather_draws(car_fit2, y_pred[i]) %>%
  ungroup() %>%
  group_by(i) %>% 
  summarize(
    bayes_car_log_pred = mean(.value)
  ) %>% 
  pull(bayes_car_log_pred)

grad_rate_modeling$bayes_car_log_resid = grad_rate_modeling$Graduation_RateH_transformed - grad_rate_modeling$bayes_car_log_pred


gridExtra::grid.arrange(
  ggplot() +  
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=bayes_car_log_pred)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Bayesian CAR Predictions", 
         subtitle = paste0("RMSE: ",
                           grad_rate_modeling$bayes_car_log_resid %>% 
                             .^2 %>% 
                             mean() %>% 
                             sqrt() %>% 
                             round(3)
         )),
  ggplot() +  
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=bayes_car_log_resid)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Bayesian CAR Residuals",
         subtitle = paste0("Moran's I: ", 
                           round(moran.test(grad_rate_modeling$bayes_car_log_resid, 
                                            listW_neigh, 
                                            na.action = na.exclude)$estimate[1],3)
         )),
  ncol=2
) 
```
# Bayesian CAR Model - Transformed & with Betas

```{r}
car_model_betas = "model{
  for(i in 1:length(y)) {
    y[i] ~ dnorm(mu[i], sigma2_w)
    y_pred[i] ~ dnorm(mu[i], sigma2_w)
    mu[i] = X[i,] %*% beta + omega[i]
  }
  
  beta[1] ~ dnorm(4,100)

  for(i in 2:7) {
    beta[i] ~ dnorm(0,0.01)
  }

  omega ~ dmnorm(rep(0,length(y)), tau * (D - phi*W))
  sigma2 = 1/tau
  tau ~ dgamma(2, 2)
  sigma2_w ~ dgamma(2, 2)
  phi ~ dunif(0,0.99)
}"
X = matrix(nrow = nrow(grad_rate), ncol = 6)
X[,1] = grad_rate_modeling$pct_hispanic
X[,2] = grad_rate_modeling$pct_white
X[,3] = grad_rate_modeling$pct_lep
X[,4] = grad_rate_modeling$English_BegH
X[,5] = grad_rate_modeling$College_Readiness
X[,6] = grad_rate_modeling$PPE
X = model.matrix(~X)

if (!file.exists("jags_car_betas.rds")) {
  m = rjags::jags.model(
    textConnection(car_model_betas),
    data = list(
      y = grad_rate_modeling$Graduation_RateH_transformed,
      X = X,
      W = W * 1,
      D = diag(rowSums(W))
    )
  )
  
  update(m, n.iter=25000)
  
  car_fit_betas = rjags::coda.samples(
    m, variable.names = c("beta", "sigma2", "sigma2_w", "omega", "tau", "phi", "y_pred"),
    n.iter=50000, thin=50
  )
  saveRDS(car_fit_betas, "jags_car_betas.rds")
} else {
  car_fit_betas = readRDS("jags_car_betas.rds")
}
```

## MCMC Diagnostics 

```{r}
tidybayes::gather_draws(car_fit_betas, beta[i]) %>% 
  ungroup() %>%
  filter(i <= 4) %>% 
  mutate(.variable = paste0(.variable, "[", i, "]")) %>%
  ggplot(aes(x = .iteration, y = .value, color = .variable)) + 
  geom_line() + 
  facet_grid(.variable~., scales= "free_y") +
  guides(color=FALSE)

tidybayes::gather_draws(car_fit_betas, beta[i]) %>% 
  ungroup() %>%
  filter(i > 4) %>% 
  mutate(.variable = paste0(.variable, "[", i, "]")) %>%
  ggplot(aes(x = .iteration, y = .value, color = .variable)) + 
  geom_line() + 
  facet_grid(.variable~., scales= "free_y") +
  guides(color=FALSE)

tidybayes::gather_draws(car_fit_betas, sigma2, sigma2_w, phi) %>% 
  ungroup() %>%
  ggplot(aes(x = .iteration, y = .value, color = .variable)) + 
  geom_line() + 
  facet_grid(.variable~., scales= "free_y") +
  guides(color=FALSE)
```

The chains look better than the chains from the previous model. 

## Prediction & Residuals

```{r}
grad_rate_modeling$bayes_car_betas_log_pred = tidybayes::gather_draws(car_fit_betas, y_pred[i]) %>%
  ungroup() %>%
  group_by(i) %>%
  summarise(
    bayes_betas_car_pred = mean(.value)
  ) %>% 
  pull(bayes_betas_car_pred)

grad_rate_modeling$bayes_car_betas_log_resid = grad_rate_modeling$Graduation_RateH_transformed - grad_rate_modeling$bayes_car_betas_log_pred

gridExtra::grid.arrange(
  ggplot() +  
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=bayes_car_betas_log_pred)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Bayesian CAR (with Betas) Predictions", 
         subtitle = paste0("RMSE: ",
                           grad_rate_modeling$bayes_car_betas_log_resid %>% 
                             .^2 %>% 
                             mean() %>% 
                             sqrt() %>% 
                             round(3)
         )),
  ggplot() +  
    geom_sf(data=init_counties, fill=NA) + 
    geom_sf(data=grad_rate_modeling, aes(fill=bayes_car_betas_log_resid)) +
    scale_fill_continuous(na.value="white") + 
    labs(title = "Bayesian CAR (with Betas) Residuals",
         subtitle = paste0("Moran's I: ", 
                           round(moran.test(grad_rate_modeling$bayes_car_betas_log_resid, 
                                            listW_neigh, 
                                            na.action = na.exclude)$estimate[1],3)
         )),
  ncol=2
) 
```

# Summary of Models 

```{r}
grad_rate_modeling %>%
  as_tibble() %>%
  select(ends_with("log_resid")) %>%
  tidyr::gather(model, resid) %>% 
  mutate(model = stringr::str_replace(model, "_resid","") %>% 
           forcats::as_factor()) %>% 
  group_by(model) %>%
  summarize(
    rmse = resid^2 %>% mean(na.rm=TRUE) %>% sqrt(),
    moran = moran.test(resid, listW_neigh, na.action = na.exclude)$estimate[1]
  ) %>%
  arrange(rmse)
```

It seems that the simple Bayesian CAR Model has the best predictive power (lowest RMSE), and the Bayesian CAR model with the `betas` has the lowest spatial autocorrelation (lowest Moran's I). Either of these models will be fine to choose as the final model. 



