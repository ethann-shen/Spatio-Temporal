---
title: "Exercises"
author: "Ethan Shen"
date: "5/13/2020"
output:
  github_document
---

```{r}
library(tidyverse)
```

# Lecture 1 

## Bayesian Linear Models 

```{r}
set.seed(129047809)
n = 100
beta = c(0.7, 1.5, -2.2, 0.1)
eps = rnorm(n)
d = data.frame(
  X1 = rt(n, df=5), # t-distribution
  X2 = rt(n, df=5),
  X3 = rt(n, df=5)
) %>%
  mutate(Y = beta[1] + beta[2]*X1 + beta[3]*X2 + beta[4]*X3 + eps)
X = cbind(1, d$X1, d$X2, d$X3)

l = lm(Y~.-Y, data = d)
l$coefficients

beta_hat = solve(t(X) %*% X, t(X) %*% d$Y)
beta_hat
```

### JAGS

```{r}
model = "model{
  # Likelihood
  for(i in 1:length(Y)){
    Y[i]   ~ dnorm(mu[i], tau) #normal distribution parametrized with precision, NOT variance 
    mu[i] = beta[1] + beta[2]*X1[i] + beta[3]*X2[i] + beta[4]*X3[i]
  }

  # Prior for beta
  for(j in 1:4){
    beta[j] ~ dnorm(0,1/100)
  }

  # Prior for sigma / tau2
  tau ~ dgamma(1, 1)
  sigma2 = 1/tau
}"

# Gibbs Sampler
m = rjags::jags.model(
  textConnection(model), 
  data = d,
  n.chains = 4
) 

update(m, n.iter=1000, progress.bar="none") # burn-in
samp = rjags::coda.samples(
  m, 
  variable.names=c("beta","sigma2"), 
  n.iter=5000, # actual samples
  progress.bar="none" 
)
```

```{r}
other = 
  bind_rows(
    tibble(
      param = paste0("beta[",1:4,"]"),
      class = "beta",
      value = beta,
      type = "true value"
    ) %>%
      rbind(list("sigma2","sigma2",1, "true value")),
    tibble(
      param = paste0("beta[",1:4,"]"),
      class = "beta",
      value = l$coefficients,
      type = "mle"
    ) %>%
      rbind(list("sigma2", "sigma2", var(l$residuals), "mle"))
  )

# non-informative priors --> converging to MLE

samp %>% 
  purrr::pluck(1) %>%
  as.data.frame() %>%
  tidyr::gather(param, value) %>%
  mutate(class = stringr::str_replace(param, "\\[\\d+\\]","")) %>%
  ggplot(aes_string(x="value", fill="class")) +
  geom_density(alpha=0.5) +
  facet_wrap(~param, scales = "free") +
  geom_vline(data = other, aes_string(xintercept="value", color="type", linetype="type"), size=0.8) +
  scale_colour_manual(values=c("grey22","grey52")) +
  guides(fill=FALSE)
```

```{r}
df_mcmc <- tidybayes::gather_draws(samp, #CODA object
                                   beta[i], 
                                   sigma2) %>%
  mutate(param = paste0(.variable, ifelse(is.na(i), "", paste0("[", i, "]")))) %>%
  group_by(param, .chain) %>%
  arrange(.iteration, .draw)

head(df_mcmc, 10) 

tail(df_mcmc, 10)

# Posterior Density Plots: between four chains, what are the posterior distributions for beta[1]? (all converge)
ggplot(df_mcmc,aes(fill=as.factor(.chain), group=.chain, x=.value)) +
  geom_density(alpha=0.5, color=NA) +
  facet_wrap(~ param, scales = "free")

# Trace Plots: well-behaved chain explores entire space 
df_mcmc %>% 
  filter(.iteration <= 500,
         param == "beta[1]" | param =="beta[2]") %>%
  ggplot(aes(x=.iteration, y=.value, color=as.factor(.chain))) +
  geom_line(alpha=0.5) +
  facet_grid(.chain~ param, scale="free_y") 

# Credible Interval of beta[i] and sigma2 (highest-density interval/hdi --> narrowest possible interval that still gives me 95% area, good for very skewed distributions, bad for bimodal distributions 
# vs. quantile interval/qi)
df_ci = tidybayes::mean_hdi(df_mcmc, 
                            .value, 
                            .width=c(0.8, 0.95) # 80% and 85% credible intervals
)

df_ci

# Caterpillar Plots 
df_ci %>% 
  filter(param == "beta[1]" | param =="beta[2]") %>%
  ggplot(aes(x = .value, y = .chain, color = as.factor(.chain))) + 
  facet_grid(param~.) + 
  tidybayes::geom_pointintervalh() # thick line is 80%, thin line is 95%
```

# Lecture 2 

## Prediction

```{r}
set.seed(01232018)
n = 100

d = data_frame(
  x = 1:n,
  y = arima.sim(n=100, list(ar=0.9,sq=1)) %>% as.numeric() + x * 0.07
)
l = lm(y ~ x, data=d)


# could add mu_pred[i] = beta[1] + beta[2] * x_pred[i]
model_pred = 
"model{
  # Likelihood
  for(i in 1:length(y)){
    mu[i] = beta[1] + beta[2]*x[i]
    y[i] ~ dnorm(mu[i], tau)
    y_pred[i] ~ dnorm(mu[i], tau) # posterior predictive distribution for y
  }

  # Prior for beta
  for(j in 1:2){
    beta[j] ~ dnorm(0,1/100)
  }

  # Prior for sigma / tau2
  tau ~ dgamma(1, 1)
  sigma2 = 1/tau
}"

n_burn = 1000; n_iter = 5000


m_pred = rjags::jags.model(
  textConnection(model_pred), data=d, 
  quiet=TRUE, n.chains = 1
) 

update(m, n.iter=n_burn, progress.bar="none")

pred = rjags::coda.samples(
  m_pred, variable.names=c("beta","sigma2","mu","y_pred","y","x"), 
  n.iter=n_iter, progress.bar="none"
)

df_pred = tidybayes::spread_draws(pred, y_pred[i], y[i], x[i], mu[i]) %>%
  mutate(resid = y - mu)

df_pred

# y_pred: full posterior predictive distribution (distribution of a new observation y_i), using uncertainty of beta1, beta2 and sigma2
# mu: where do we expect point to fall in on average, using uncertainty of beta1, beta2)
df_pred %>% 
  ungroup() %>% 
  filter(i %in% c(1,50,100)) %>% 
  select(i, mu, y_pred) %>% 
  tidyr::gather(param, val, -i) %>%
  ggplot(aes(x=val, fill=param)) + 
  geom_density(alpha=0.5) + 
  facet_wrap(~i)
```

### Residuals 

Important because with spatial-temporal data, we rarely have IID assumption

```{r}
# do not want to see this 
df_pred %>% 
  ungroup() %>%
  ggplot(aes(x=x, y=resid)) + 
  geom_boxplot(aes(group=x), outlier.alpha = 0.2)
```

## Model Evaluation (Bayesian R^2)

```{r}
df_R2 = df_pred %>%
  group_by(.iteration) %>%
  summarize(
    R2_classic = var(mu) / var(y),
    R2_bayes   = var(mu) / (var(mu) + var(resid))
  )

df_R2 %>% 
  tidyr::gather(method, R2, -.iteration) %>%
  ggplot(aes(x=R2, fill=method)) + 
    geom_density(alpha=0.5) +
    geom_vline(xintercept=summary(l)$r.squared, size=1)
```

Issue.... Bayesian $R^2 > 1$. Cannot use $R^2$ in Bayesian context. 

