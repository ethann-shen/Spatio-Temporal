---
title: "Lecture 15 - GPs for GLMs and Spatial Data"
author: "Ethan Shen"
date: "5/26/2020"
output: 
  html_document:
    keep_md: TRUE
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(patchwork)

ggplot2::theme_set(ggplot2::theme_bw())

source("../util.R")
```

# Logistic Model Example 

```{r}
set.seed(20180308)
n=200

eta = function(x) 2.5*sin(2.1*pi*(x-0.25)) 

d = data_frame(x=runif(n)) %>%
  mutate(
    eta = eta(x),
    prob = inv_logit(eta(x)),
    y = rbinom(length(x), size=1, prob = inv_logit(eta(x)))
  )

(ggplot(d, aes(x=x, y=eta)) + geom_line() + labs(title="Untransformed") + 
    ggplot(d, aes(x=x, y=prob)) + geom_line() + labs(title="Transformed"))  / 
  (ggplot(d, aes(x=x, y=y)) + geom_jitter(height = 0.05))
```

### JAGS

```{r}
logistic_model = "model{
  for(i in 1:length(y)) {
    y[i] ~ dbern(p[i])
    logit(p[i]) = beta0 + w[i]
  }

  w ~ dmnorm(rep(0,length(y)), inverse(Sigma)) # GP, mean 0 multivariate procses

  for (i in 1:(length(y)-1)) {
    for (j in (i+1):length(y)) {
    
    # exponential covariance
    
      Sigma[i,j] = sigma2 * exp(- l * d[i,j]) 
      Sigma[j,i] = Sigma[i,j]
    }
  }

  for (i in 1:length(y)) {
    Sigma[i,i] = sigma2
  }  
  
  beta0 ~ dnorm(0, 1)
  sigma2 = 1/tau
  tau ~ dgamma(1, 2)
  l ~ dunif(3/0.5, 3/0.01)
}"

if (!file.exists("jags_logistic_model.rds")) {
  m_JAGS = rjags::jags.model(
    textConnection(logistic_model),
    data = list(
      y = (d$y),
      d = dist(d$eta) %>% as.matrix()
    )
  )
  
  update(m_JAGS, n.iter=5000)
  
  JAGS_samps = rjags::coda.samples(
    m_JAGS, variable.names=c("beta0", "l", "sigma2"),
    n.iter=10000
  )
  saveRDS(JAGS_samps, file="jags_logistic_model.rds")
} else {
  JAGS_samps = readRDS("jags_logistic_model.rds")
}
```

This takes too long to sample with JAGS. 

### JAGS Model Diagnostics 

```{r}
tidybayes::gather_draws(JAGS_samps, beta0, l, sigma2) %>%
  filter(row_number() %% 10 == 1) %>%
  mutate(.iteration = floor(.iteration / 10) + 1) %>%
  ggplot(aes(x = .iteration, y = .value, color = .variable)) + 
  geom_line() + 
  facet_grid(.variable~., scales='free_y')
```

### spBayes

```{r}
y = d$y
x = d$x

coords = cbind(x, 0)
n = nrow(coords)

n.batch = 200
batch.length = 100

n.samples = n.batch * batch.length
burnin = n.samples*0.5 + 1
thin = 10

if (!file.exists("logistic_model.rds")) {
  m_spBayes = spBayes::spGLM(
    y~1, family="binomial", coords=coords,
    starting=list("beta"=0, "phi"=3/0.053,"sigma.sq"=1, "w"=0),
    tuning=list("beta"=0.5, "phi"=0.5, "sigma.sq"=0.5, "w"=0.5),
    priors=list("beta.Normal"=list(0,1), "phi.Unif"=c(3/0.5, 3/0.01), "sigma.sq.IG"=c(2, 1)),
    amcmc=list("n.batch"=n.batch, "batch.length"=batch.length, "accept.rate"=0.43),
    cov.model="exponential", verbose=TRUE, n.report=10)
  
  saveRDS(m_spBayes, file="logistic_model.rds")
} else {
  m_spBayes = readRDS("logistic_model.rds")
}
```

### spBayes Model Diagnostics 

```{r}
mcmc = m_spBayes$p.beta.theta.samples %>% 
  window(start = burnin, thin = thin) %>%
  tidybayes::gather_draws(`(Intercept)`, phi, sigma.sq)

ggplot(mcmc, aes(x=.iteration, y=.value, color=.variable)) +
  geom_line() +
  facet_grid(.variable~., scales = "free_y") +
  guides(color=FALSE)
```

phi is range parameter 

### spBayes Model Fit 

```{r}
pred = spBayes::spPredict(m_spBayes, pred.coords = coords, pred.covars = matrix(rep(1,n)), start = burnin, thin=thin, verbose = FALSE)

pred = cbind(
  t(pred$p.w.predictive.samples),
  t(pred$p.y.predictive.samples)
) 
colnames(pred) = c(paste0("eta[",1:n,"]"), paste0("p[",1:n,"]"))

tidybayes::gather_draws(pred, eta[i],p[i]) %>%
  full_join(
    select(d, x) %>% mutate(i = 1:n()),
    by = "i"
  ) %>%
  ungroup() %>%
  mutate(.variable = case_when(
    .variable=="p" ~ "prob",
    TRUE~as.character(.variable))
    ) %>%
  ggplot(aes(x=x, y=.value)) +
  tidybayes::stat_lineribbon(alpha=0.5, color="red") +
  geom_line(data=tidyr::gather(d, .variable, .value, -x, -y), size=2, linetype=2) +
  facet_wrap(~.variable, scales = "free_y")
```

In the original data, there are a couple of points that are near 0 for `x` = 0.5. This is why the red line dips in the `prob` plot, which drags down the plot. Also, exp covariance function doesn't have to be smooth.

## Model vs GLM

```{r}
g = glm(y~poly(x,2), data=d, family="binomial")
```

```{r echo=FALSE}
rbind(
  mutate(d, type = "truth"),
  mutate(d, 
    type = "glm prediction",
    eta = predict(g, type="link"),
    prob = predict(g, type="response")
  )
) %>% 
  tidyr::gather(term, estimate, -x, -y, -type) %>%
  ggplot(aes(x=x, y=estimate, color=type, linetype=type)) +
    geom_line(size=2) +
    facet_wrap(~term, scales = "free_y") +
    scale_color_manual(values = c("red","black"))
```

This GLM has to be smooth because we are fitting a quadratic GLM. However, it can't flatten out at the tails. 

# Spatial Data 


